{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f991df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import efficientnet_pytorch\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f41e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomEfficientNet, self).__init__()\n",
    "        self.base_model = efficientnet_pytorch.EfficientNet.from_pretrained(\n",
    "            'efficientnet-b0'\n",
    "        )\n",
    "        self.base_model._fc = nn.Linear(\n",
    "            in_features=self.base_model._fc.in_features, \n",
    "            out_features=1, \n",
    "            bias=True\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ff5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.001, verbose=True):\n",
    "        self.patience = patience # Num of epochs to wait\n",
    "        self.delta = delta # Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        self.verbose = verbose # print message for each validation loss improvement or not\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), f'./results/{train_name}/{train_name}-vloss{self.val_loss_min}.pth')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a6f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmeanstd(dataroot, img_h, img_w,batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_h, img_w)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    dataset = ImageFolder(dataroot, transform=transform)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the variables for calculating mean and std\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    num_images = 0\n",
    "\n",
    "    # Calculate the mean for each channel\n",
    "    for images, _ in data_loader:\n",
    "        num_images += images.size(0)\n",
    "        mean += torch.mean(images, dim=(0, 2, 3))\n",
    "\n",
    "    mean /= num_images\n",
    "\n",
    "    # Calculate the standard deviation for each channel\n",
    "    for images, _ in data_loader:\n",
    "        std += torch.mean((images - mean.view(1, 3, 1, 1)) ** 2, dim=(0, 2, 3))\n",
    "\n",
    "    std = torch.sqrt(std / num_images)\n",
    "    print(\"Dataset: \", dataroot)\n",
    "    print(\"Mean values: \", mean)\n",
    "    print(\"Standard deviation values: \", std)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7217d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"vit_l_32\",  # \"vit_l_32\" or \"swin_v2_b\" or \"efficientnet_b0\"\n",
    "    \"criterion\": \"BCEWithLogitsLoss\", # \"BCEWithLogitsLoss\" or \"BCELoss\"\n",
    "    \"scheduler\": \"exponential\", # \"none\" or \"exponential\" or \"multistep\"\n",
    "    \"pretrained\": True,         # Set False for training from scratch\n",
    "    \"data_root\": \"./Dataset\",\n",
    "    \"batch_size\": 32,            # 16\n",
    "    \"num_epochs\": 10,            # 10\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"gpus\": [1],               # Default is GPU 0, change to [0, 1] for both GPUs\n",
    "    \"output_dir\": \"./results\",\n",
    "    \"early_stopping\": True,\n",
    "    \"patience\": 5,\n",
    "    \"delta\": 0.001,\n",
    "    \"es_verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0cd569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "early_stopper = EarlyStopping(config[\"patience\"], config[\"delta\"], config[\"es_verbose\"])\n",
    "\n",
    "if config[\"model_name\"].lower() == \"vit_l_32\":\n",
    "    model = models.vit_l_32(weights=models.ViT_L_32_Weights.DEFAULT if config[\"pretrained\"] else None)\n",
    "    num_features = model.heads.head.in_features\n",
    "    model.heads.head = nn.Linear(num_features, 1)\n",
    "elif config[\"model_name\"].lower() == \"swin_v2_b\":\n",
    "    model = models.swin_v2_b(weights=models.Swin_V2_B_Weights.DEFAULT if config[\"pretrained\"] else None)\n",
    "    num_features = model.head.in_features\n",
    "    model.head = nn.Linear(num_features, 1)\n",
    "elif config[\"model_name\"].lower() == \"efficientnet_b0\":\n",
    "    model = CustomEfficientNet()\n",
    "else:\n",
    "    raise ValueError(\"Unsupported model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83494d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "\n",
    "if config[\"model_name\"].lower()[:3] == \"vit\" or config[\"model_name\"] == \"efficientnet_b0\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.0291, 0.0269, 0.0253], [0.1319, 0.1239, 0.1194]),\n",
    "        # to save computation cost use pre calculated mean and std here, for other datasets use getmeanstd()\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.0291, 0.0269, 0.0253], [0.1319, 0.1239, 0.1194]),\n",
    "        # to save computation cost use pre calculated mean and std here, for other datasets use getmeanstd()\n",
    "    ])\n",
    "\"\"\"\n",
    "Pre calculated mean and std on provided:\n",
    "Mean values:  tensor([0.0291, 0.0269, 0.0253])\n",
    "Standard deviation values:  tensor([0.1319, 0.1239, 0.1194])\n",
    "([0.0291, 0.0269, 0.0253]),([0.1319, 0.1239, 0.1194])\n",
    "\"\"\"\n",
    "train_dataset = datasets.ImageFolder(os.path.join(config[\"data_root\"], \"train\"), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(config[\"data_root\"], \"val\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f709f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "device = torch.device(f\"cuda:{config['gpus'][0]}\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "if len(config[\"gpus\"]) > 1:\n",
    "    model = nn.DataParallel(model, device_ids=config[\"gpus\"])\n",
    "\n",
    "def get_criterion():\n",
    "    if config[\"criterion\"].lower() == \"bcewithlogitsloss\":\n",
    "        return nn.BCEWithLogitsLoss()\n",
    "    elif config[\"criterion\"].lower() == \"bceloss\":\n",
    "        return nn.BCELoss()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported loss function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a42055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = get_criterion()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc322871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scheduler for dynamic learning_rate\n",
    "def get_scheduler():\n",
    "    if config[\"scheduler\"] == \"none\":\n",
    "        return None\n",
    "    elif config[\"scheduler\"] == \"exponential\":\n",
    "        return optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5) # lr = lr*gamma**epoch\n",
    "    elif config[\"scheduler\"] == \"multistep\":\n",
    "        return optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,8], gamma=0.1)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f300c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Function\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch} [TRAIN]\", leave=False)\n",
    "    scheduler = get_scheduler()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        images, labels = images.to(device), labels.to(device).float()\n",
    "        labels = labels.unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predictions = torch.sigmoid(outputs) > 0.5\n",
    "        total_correct += predictions.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        loss=total_loss/(total_samples/config[\"batch_size\"])\n",
    "        acc=total_correct/total_samples\n",
    "        progress_bar.set_postfix(loss=loss, acc=acc)\n",
    "\n",
    "    # Update scheduler\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_acc = total_correct / total_samples\n",
    "    print(f\"Train Epoch: {epoch} Loss: {avg_loss:.4f} Acc: {avg_acc:.4f}\")\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "457b25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "    progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch} [VALID]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(progress_bar):\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            labels = labels.unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.sigmoid(outputs) > 0.5\n",
    "            total_correct += predictions.eq(labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            loss=total_loss/(total_samples/config[\"batch_size\"])\n",
    "            acc=total_correct/total_samples\n",
    "            progress_bar.set_postfix(loss=loss, acc=acc)\n",
    "\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_acc = total_correct / total_samples\n",
    "    print(f\"Val Epoch: {epoch} Loss: {avg_loss:.4f} Acc: {avg_acc:.4f}\")\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69d50bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Setup\n",
    "train_name = config[\"model_name\"]+'-'+datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "output_folder = os.path.join(config[\"output_dir\"], train_name)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "log_file = os.path.join(output_folder, f\"{train_name}-training_log.txt\")\n",
    "\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"Training Configuration:\\n\")\n",
    "    for key, value in config.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30224bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    train_loss, train_acc = train(epoch)\n",
    "    val_loss, val_acc = validate(epoch)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    print(f\"Epoch {epoch}: Train Loss: {train_loss}, Train Acc: {train_acc}, Val Loss: {val_loss}, Val Acc: {val_acc}\\n\")\n",
    "    \n",
    "    # Update EarlyStopping and check for early stop condition\n",
    "    if config[\"early_stopping\"] == True:\n",
    "        early_stopper(val_loss, model)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    # Logging\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"Epoch {epoch}: Train Loss: {train_loss}, Train Acc: {train_acc}, Val Loss: {val_loss}, Val Acc: {val_acc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(output_folder, f\"{train_name}.pth\")\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82cf9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train Acc')\n",
    "plt.plot(val_accs, label='Val Acc')\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "filename = f\"{train_name}-metrics.png\"\n",
    "plt.savefig(os.path.join(output_folder, filename))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
